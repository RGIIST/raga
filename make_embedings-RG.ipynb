{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2cc420-80f0-4d5a-bcb0-d870ea0e3105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0678a10-5777-43bd-88c8-fa66244d6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = \"LM_FF_Mar_28_2_2022_Speed_Stop_Vehicle_416_256.weights\"\n",
    "cfg_file = \"LM_FF_America_Speed_Stop_vehicles_416_256.cfg\"\n",
    "class_file = \"class.txt\"\n",
    "img_size=(416,256)\n",
    "\n",
    "# weights_file = \"TinyYolov3/Weight_files/yolov3-tiny-america_best.weights\"\n",
    "# cfg_file = \"TinyYolov3/Cfg_files/yolov3-tiny-america.cfg\"\n",
    "# class_file=\"TinyYolov3/Class_files/america_classes.txt\"\n",
    "# img_size=(416,416)\n",
    "\n",
    "scale=0.00392\n",
    "fps=10.0\n",
    "W,H=640, 360\n",
    "Width,Height=640, 360\n",
    "\n",
    "# vid_path=os.path.join('../../../datasets/lightmetrics_data/videos_dataset/HarshBraking',\n",
    "# 'eventVideo_sensor_Harsh-Braking_trip_master_2022_03_15_00_27_24_887_A7F144D8F6A1255B7D44B5B861A28475AB24F23B_VgHgv_4_1647305450748_primary_2022_03_15_00_50_50_748.mp4')\n",
    "net = cv2.dnn.readNet(weights_file,cfg_file)\n",
    "with open(class_file, 'r') as f:\n",
    "    america_class_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(america_class_names), 3))\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers\n",
    "\n",
    "def draw_bounding_box(img, cnames, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "    label = str(cnames[class_id])\n",
    "    color = COLORS[class_id]\n",
    "    cv2.rectangle(img, (x, y), (x_plus_w, y_plus_h), color, 2)\n",
    "    cv2.putText(img, label, (x-10, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "281f0199-3fd8-4646-89ca-faad1d360e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(vid_path)\n",
    "# vid_out=cv2.VideoWriter(\"dataset/Braking_trip_master_2022_03_15_00_27_24_887_A7F144D8F6A1255B7D44B5B861A28475AB24F23B_VgHgv_4_1647305450748_primary_2022_03_15_00_50_50_748.mp4\",cv2.VideoWriter_fourcc(*'mp4v'),fps,(W,H))\n",
    "# while True:\n",
    "#     ret,color_img=cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "#     # image=color_img\n",
    "#     image= cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)\n",
    "#     blob = cv2.dnn.blobFromImage(image, scale, img_size, (0,0,0), True, crop=False)\n",
    "#     net.setInput(blob)\n",
    "#     outs = net.forward(get_output_layers(net))\n",
    "#     class_ids = []\n",
    "#     confidences = []\n",
    "#     boxes = []\n",
    "#     conf_threshold = 0.3\n",
    "#     nms_threshold = 0.4\n",
    "#     count = 0\n",
    "#     for out in outs:\n",
    "#         for detection in out:\n",
    "#             scores=detection[5:]\n",
    "#             count += 1\n",
    "#             class_id = np.argmax(scores)\n",
    "#             confidence = scores[class_id]\n",
    "#             if confidence > conf_threshold:\n",
    "#                 center_x = int(detection[0] * Width)\n",
    "#                 center_y = int(detection[1] * Height)\n",
    "#                 w = int(detection[2] * Width)\n",
    "#                 h = int(detection[3] * Height)\n",
    "#                 x = center_x - w / 2\n",
    "#                 y = center_y - h / 2\n",
    "#                 class_ids.append(class_id)\n",
    "#                 confidences.append(float(confidence))\n",
    "#                 boxes.append([x, y, w, h])\n",
    "#     indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "#     drawn_image = color_img\n",
    "\n",
    "#     for i in indices:\n",
    "#         number = 0\n",
    "#         box = boxes[i]\n",
    "#         x = max(int(box[0]),0)\n",
    "#         y = max(int(box[1]),0)\n",
    "#         w = int(box[2])\n",
    "#         h = int(box[3])\n",
    "\n",
    "#         if(class_ids[i] == 0 or class_ids[i] == 1 or class_ids[i] == 2):\n",
    "#             drawn_image = draw_bounding_box(color_img, america_class_names, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
    "#     vid_out.write(drawn_image)\n",
    "            \n",
    "# cap.release()\n",
    "# vid_out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c30c56-dd92-4e5b-9b46-37977af2c3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1773it [1:25:30,  2.78s/it]"
     ]
    }
   ],
   "source": [
    "folders=os.listdir('../../../datasets/lightmetrics_data/videos_dataset')\n",
    "folders.remove('Untitled.ipynb')\n",
    "vid_out=cv2.VideoWriter(\"dataset/videos/LM_FF_America.mp4\",cv2.VideoWriter_fourcc(*'mp4v'),fps,(W,H))\n",
    "for folder in folders:\n",
    "    videos=os.listdir(os.path.join('../../../datasets/lightmetrics_data/videos_dataset',folder))\n",
    "    for video_num,video in tqdm(enumerate(videos)):\n",
    "        if 'mp4' in video:\n",
    "            cap = cv2.VideoCapture(os.path.join('../../../datasets/lightmetrics_data/videos_dataset',folder,video))\n",
    "            frame=0\n",
    "            while True:\n",
    "                ret,color_img=cap.read()\n",
    "                frame+=1\n",
    "                if not ret:\n",
    "                    break\n",
    "                # image=color_img   # Uncomment for tinyyolo, comment for LM_FF\n",
    "                image= cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)  # comment for tinyyolo, Uncomment for LM_FF\n",
    "                blob = cv2.dnn.blobFromImage(image, scale, img_size, (0,0,0), True, crop=False)\n",
    "                net.setInput(blob)\n",
    "                outs = net.forward(get_output_layers(net))\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "                conf_threshold = 0.3\n",
    "                nms_threshold = 0.4\n",
    "                count = 0\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores=detection[5:]\n",
    "                        count += 1\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > conf_threshold:\n",
    "                            center_x = int(detection[0] * Width)\n",
    "                            center_y = int(detection[1] * Height)\n",
    "                            w = int(detection[2] * Width)\n",
    "                            h = int(detection[3] * Height)\n",
    "                            x = center_x - w / 2\n",
    "                            y = center_y - h / 2\n",
    "                            class_ids.append(class_id)\n",
    "                            confidences.append(float(confidence))\n",
    "                            boxes.append([x, y, w, h])\n",
    "                indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "                drawn_image = color_img\n",
    "\n",
    "                for i in indices:\n",
    "                    number = 0\n",
    "                    box = boxes[i]\n",
    "                    x = max(int(box[0]),0)\n",
    "                    y = max(int(box[1]),0)\n",
    "                    w = int(box[2])\n",
    "                    h = int(box[3])\n",
    "\n",
    "                    if(class_ids[i] == 0 or class_ids[i] == 1 or class_ids[i] == 2):\n",
    "                        drawn_image = draw_bounding_box(color_img, america_class_names, class_ids[i], confidences[i],\n",
    "                                                        round(x), round(y), round(x+w), round(y+h))\n",
    "                cv2.putText(drawn_image,'{} video: {},frame: {}'.format(folder,video_num+1,frame),\n",
    "                            (0,13),cv2.FONT_HERSHEY_COMPLEX_SMALL,0.9,(0, 155, 155),1)\n",
    "                vid_out.write(drawn_image)\n",
    "\n",
    "            cap.release()\n",
    "vid_out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1b8b224b-dfc2-4a57-8e24-762232da1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file1 = \"TinyYolov3/Weight_files/yolov3-tiny-america_best.weights\"\n",
    "cfg_file1 = \"TinyYolov3/Cfg_files/yolov3-tiny-america.cfg\"\n",
    "class_file1=\"TinyYolov3/Class_files/america_classes.txt\"\n",
    "img_size1=(416,416)\n",
    "\n",
    "weights_file2 = \"LM_FF_Mar_28_2_2022_Speed_Stop_Vehicle_416_256.weights\"\n",
    "cfg_file2 = \"LM_FF_America_Speed_Stop_vehicles_416_256.cfg\"\n",
    "class_file2 = \"class.txt\"\n",
    "img_size2=(416,256)\n",
    "image1=cv2.imread('Image_S16_5.jpg')\n",
    "image2=cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "net1 = cv2.dnn.readNet(weights_file1,cfg_file1)\n",
    "net2 = cv2.dnn.readNet(weights_file2,cfg_file2)\n",
    "blob1 = cv2.dnn.blobFromImage(image1, scale, img_size1, (0,0,0), True, crop=False)\n",
    "net1.setInput(blob1)\n",
    "blob2 = cv2.dnn.blobFromImage(image2, scale, img_size2, (0,0,0), True, crop=False)\n",
    "net2.setInput(blob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0482b344-f28d-45f4-8d47-9ec16f0afd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 16, 26)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.forward(net2.getLayerNames()[-4]).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0783a4e3-0c31-49a0-8e1c-dfbcb5f295fd",
   "metadata": {},
   "source": [
    "## Embeddings and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "242ef019-09a3-4ddf-855b-883f21c37cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, json\n",
    "from mmcls.datasets import build_dataloader, build_dataset\n",
    "from mmcls.models import build_classifier\n",
    "import os, cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "c27bb7e0-7e00-4081-8c27-674a1cce3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=torch.load('TinyYolov3/resnet50/resnet50_5x_224x224_weather_tag_bdd100k.pth')\n",
    "model1 = torch.hub.load(\"pytorch/vision\", \"resnet50\", weights=file['state_dict'])\n",
    "model2=build_classifier(dict(\n",
    "    type=\"ImageClassifier\",\n",
    "    backbone=dict(\n",
    "        type=\"ResNet\",\n",
    "        depth=50,\n",
    "        num_stages=4,\n",
    "        out_indices=(3,),\n",
    "        style=\"pytorch\",\n",
    "    ),\n",
    "    neck=dict(type=\"GlobalAveragePooling\"),\n",
    "    head=dict(\n",
    "        type=\"LinearClsHead\",\n",
    "        num_classes=7,\n",
    "        in_channels=2048,\n",
    "        loss=dict(type=\"CrossEntropyLoss\", loss_weight=1.0),\n",
    "    ),\n",
    "))\n",
    "model2.load_state_dict(file['state_dict'])\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c52655b7-7d95-4cdf-9d1b-1e2e6bd3721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Files=['hb.json','ss.json','tg.json']\n",
    "gt=[]\n",
    "for File in Files:\n",
    "    with open(File,'r') as f:\n",
    "        gt.extend(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "424efa19-36e8-459d-97eb-0909d7febf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sunny'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "989131c4-0c24-4703-a77b-9d6c35a7a0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 2092/2092 [1:02:47<00:00,  1.80s/it]\n",
      "100% 1463/1463 [47:26<00:00,  1.95s/it]\n",
      "100% 4602/4602 [2:40:02<00:00,  2.09s/it]  \n",
      "100% 1/1 [00:00<00:00, 5974.79it/s]\n",
      "100% 215/215 [00:00<00:00, 866258.75it/s]\n"
     ]
    }
   ],
   "source": [
    "CLASSES=['rainy', 'snowy', 'clear', 'overcast', 'undefined', 'partly cloudy', 'foggy']\n",
    "folders=os.listdir('../../../datasets/lightmetrics_data/videos_dataset')\n",
    "folders.remove('Untitled.ipynb')\n",
    "embedding=[]\n",
    "lengt=len(gt)\n",
    "final={'video':[],'embedding':[],'inference':[],'prediction':[],'gt':[]}\n",
    "for folder in folders:\n",
    "    videos=os.listdir(os.path.join('../../../datasets/lightmetrics_data/videos_dataset',folder))\n",
    "    for video in tqdm(videos):\n",
    "        if 'mp4' in video:\n",
    "            embeddings,inference,pred_cls,gt_label=[],[],[],[]\n",
    "            cap = cv2.VideoCapture(os.path.join('../../../datasets/lightmetrics_data/videos_dataset',folder,video))\n",
    "            frame=0\n",
    "            while True:\n",
    "                ret,color_img=cap.read()\n",
    "                frame+=10\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "                if not ret:\n",
    "                    break\n",
    "                color_img=np.array(cv2.resize(color_img,(224,224)),dtype=np.float32)\n",
    "                out1=model1(torch.from_numpy(color_img).view(1,3,224,224))\n",
    "                out2=model2.forward_test(torch.from_numpy(color_img).view(1,3,224,224))\n",
    "                embeddings.append(out1[0].tolist())\n",
    "                embedding.append(out1[0].tolist())\n",
    "                inference.append(out2[0].tolist())\n",
    "                pred_cls.append(CLASSES[np.argmax(out2)])\n",
    "                for i in range(lengt):\n",
    "                    if gt[i]['inputs'][0]==video:\n",
    "                        gt_label.append(gt[i]['attributes']['weather'])\n",
    "                        break\n",
    "            cap.release()\n",
    "            final['video'].append(video)\n",
    "            final['embedding'].append(embeddings)\n",
    "            final['inference'].append(inference)\n",
    "            final['prediction'].append(pred_cls)\n",
    "            final['gt'].append(gt_label)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "096ecac6-7157-40b6-9200-224483771299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8157, 8373)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final['video']),2092+1463+4602+1+215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4e65c6d0-d560-449d-8b53-2982e36953f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_light=pd.DataFrame(final)#.to_csv('lightmetrics.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2a05a72d-6088-4826-b2b4-f9866c592fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fcab4cca-46db-4024-b6a0-b1b937ce875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dimesion=2\n",
    "reducer = UMAP(n_components=embed_dimesion, random_state=42)\n",
    "embed1 = reducer.fit_transform(StandardScaler().fit_transform(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9abc50d5-b2cf-4169-a54c-6e4a2faf8a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure()\n",
    "f.set_figwidth(10)\n",
    "f.set_figheight(10)\n",
    "plt.title(\"lightMetrics embeddings\")\n",
    "plt.scatter(embed1[:,0],embed1[:,1])  #,c=labels\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "672534de-189e-485a-8473-3cf3754ba04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94421, 94421)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding),len(embed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03460b7-5030-440b-b669-abd15f51ecac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bb9ca966-ea06-4682-93f8-14f2ca130bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8157it [00:04, 2030.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# frame=10\n",
    "final_result={'video_name':[],'folder_name':[],'predicted_class':[]}\n",
    "HarshBraking=os.listdir(os.path.join('../../../datasets/lightmetrics_data/videos_dataset','HarshBraking'))\n",
    "TailGating=os.listdir(os.path.join('../../../datasets/lightmetrics_data/videos_dataset','TailGating'))\n",
    "StopSign=os.listdir(os.path.join('../../../datasets/lightmetrics_data/videos_dataset','StopSign'))\n",
    "SpeedSign=os.listdir(os.path.join('../../../datasets/lightmetrics_data/videos_dataset','SpeedSign'))\n",
    "\n",
    "for i in range(1000):\n",
    "    final_result[str(i)]=[]\n",
    "# for folder in folders:\n",
    "#     videos=os.listdir(os.path.join('../../../datasets/lightmetrics_data/videos_dataset',folder))\n",
    "#     for video in tqdm(videos):\n",
    "#         if 'mp4' in video:\n",
    "#             cap = cv2.VideoCapture(os.path.join('../../../datasets/lightmetrics_data/videos_dataset',folder,video)) \n",
    "#             while True:\n",
    "#                 cap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "#                 ret,image=cap.read()\n",
    "#                 if not ret:\n",
    "#                     frame-=1\n",
    "#                     continue\n",
    "#                     if frame<0:\n",
    "#                         break\n",
    "#                 else:\n",
    "#                     frame=10\n",
    "#                     break\n",
    "#             image=np.array(cv2.resize(image,(224,224)),dtype=np.float32)\n",
    "#             out1=model1(torch.from_numpy(image).view(1,3,224,224))\n",
    "#             out2=model2.forward_test(torch.from_numpy(image).view(1,3,224,224))\n",
    "#             final_result['video_name'].append(video)\n",
    "#             final_result['folder_name'].append(folder)\n",
    "#             final_result['predicted_class'].append(CLASSES[np.argmax(out2)])\n",
    "#             for i in range(1000):\n",
    "#                 final_result[str(i)].append(out1[0][i].item())\n",
    "#             cap.release()\n",
    "\n",
    "for i,video in tqdm(enumerate(final['video'])):\n",
    "    final_result['video_name'].append(video)    \n",
    "    if video in HarshBraking:\n",
    "        final_result['folder_name'].append('HarshBraking')\n",
    "    elif video in TailGating:\n",
    "        final_result['folder_name'].append('TailGating')\n",
    "    elif video in StopSign:\n",
    "        final_result['folder_name'].append('StopSign')\n",
    "    elif video in SpeedSign:\n",
    "        final_result['folder_name'].append('SpeedSign')\n",
    "        \n",
    "    if len(final['embedding'][i])>1:\n",
    "        final_result['predicted_class'].append(final['prediction'][i][1])\n",
    "        emb=final['embedding'][i][1]\n",
    "        for j in range(1000):\n",
    "            final_result[str(j)].append(emb[j])\n",
    "    else:\n",
    "        final_result['predicted_class'].append(final['prediction'][i][0])\n",
    "        emb=final['embedding'][i][0]\n",
    "        for j in range(1000):\n",
    "            final_result[str(j)].append(emb[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ed4bf3bb-7a7a-4fe5-81f5-788e07b7dca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d4166366-bd9a-4c6a-b562-92180b0c2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "# from moviepy.editor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f9db54fb-d532-4398-a46b-4a4f71d19b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/project/a100/rahul/Yolo/Yolo/Foggy weather.mp4'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link=\"https://www.youtube.com/watch?v=wlgClFPZg6w\"\n",
    "YouTube(link).streams.filter(only_video=True,file_extension='mp4').first().download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "4c9a3ddf-a97a-4e4e-927b-31d234fb2b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 1., 0., 0., 0., 0., 0.], dtype=float32)]\n",
      "[array([0., 1., 0., 0., 0., 0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(\"foggy.mp4\")\n",
    "frame=250\n",
    "img_size=(640,640)\n",
    "pred_cls=[]\n",
    "while True:\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "    ret,image=cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    frame+=100\n",
    "    image=np.array(cv2.resize(image,img_size),dtype=np.float32)\n",
    "    out2=model2.forward_test(torch.from_numpy(image).view(1,3,img_size[0],img_size[1]))\n",
    "    pred_cls.append(CLASSES[np.argmax(out2)])\n",
    "    print(out2)\n",
    "    \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706604ff-4054-4c3a-8f50-21fb6f045946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_file1 = \"LM_FF_Mar_28_2_2022_Speed_Stop_Vehicle_416_256.weights\"\n",
    "# cfg_file1 = \"LM_FF_America_Speed_Stop_vehicles_416_256.cfg\"\n",
    "# class_file1 = \"class.txt\"\n",
    "img_size1=(416,256)\n",
    "\n",
    "weights_file2 = \"TinyYolov3/Weight_files/yolov3-tiny-america_best.weights\"\n",
    "cfg_file2 = \"TinyYolov3/Cfg_files/yolov3-tiny-america.cfg\"\n",
    "class_file2=\"TinyYolov3/Class_files/america_classes.txt\"\n",
    "img_size2=(416,416)\n",
    "\n",
    "scale=0.00392\n",
    "fps=10.0\n",
    "W,H=640, 360\n",
    "Width,Height=640, 360\n",
    "classes = ['USSpeedSign', 'StopSign', 'Vehicle']\n",
    "\n",
    "with open('../../false_pos.pickle' ,'rb') as f:\n",
    "    false_pos = pickle.load(f)\n",
    "\n",
    "# with open('img_idx.pickle', 'rb') as f:\n",
    "#   img_idx = pickle.load(f)\n",
    "\n",
    "# img, idx = img_idx['imname']\n",
    "\n",
    "# fp_idx = np.load('../../fp_idx.npy')\n",
    "\n",
    "# images_a = visual['images']\n",
    "\n",
    "im_pic = false_pos['images']\n",
    "idxs, imname = false_pos['idxs'], false_pos['imname']\n",
    "# net1 = cv2.dnn.readNet(weights_file1,cfg_file1)\n",
    "net1 = cv2.dnn.readNet(weights_file2,cfg_file2)\n",
    "with open(class_file2, 'r') as f:\n",
    "    america_class_names1 = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# with open(class_file1, 'r') as f:\n",
    "#     america_class_names1 = [line.strip() for line in f.readlines()]\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(america_class_names2), 3))\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers\n",
    "\n",
    "def draw_bounding_box(img, cnames, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "    label = str(cnames[class_id])\n",
    "    color = COLORS[class_id]\n",
    "    cv2.rectangle(img, (x, y), (x_plus_w, y_plus_h), color, 2)\n",
    "    cv2.putText(img, label, (x-10, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbbfa809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:33<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "vid_out=cv2.VideoWriter(\"false_pos.mp4\",cv2.VideoWriter_fourcc(*'mp4v'),1,(W,H))\n",
    "for img_name in tqdm(im_pic.keys()):\n",
    "    image = np.array(im_pic[img_name], dtype=np.uint8)\n",
    "    gray_image= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blob1 = cv2.dnn.blobFromImage(gray_image, scale, img_size1, (0,0,0), True, crop=False)\n",
    "    blob2 = cv2.dnn.blobFromImage(image, scale, img_size2, (0,0,0), True, crop=False)\n",
    "    net1.setInput(blob1)\n",
    "    net2.setInput(blob2)\n",
    "    outs1 = net1.forward(get_output_layers(net1))\n",
    "    outs2 = net2.forward(get_output_layers(net2))\n",
    "    class_ids1 = []\n",
    "    confidences1 = []\n",
    "    boxes1 = []\n",
    "    conf_threshold = 0.3\n",
    "    nms_threshold = 0.4\n",
    "    count1 = 0\n",
    "    for out1 in outs1:\n",
    "        for detection1 in out1:\n",
    "            scores1=detection1[5:]\n",
    "            count1 += 1\n",
    "            class_id1 = np.argmax(scores1)\n",
    "            confidence1 = scores1[class_id1]\n",
    "            if confidence1 > conf_threshold:\n",
    "                center_x = int(detection1[0] * Width)\n",
    "                center_y = int(detection1[1] * Height)\n",
    "                w = int(detection1[2] * Width)\n",
    "                h = int(detection1[3] * Height)\n",
    "                x = center_x - w / 2\n",
    "                y = center_y - h / 2\n",
    "                class_ids1.append(class_id1)\n",
    "                confidences1.append(float(confidence1))\n",
    "                boxes1.append([x, y, w, h])\n",
    "    indices1 = cv2.dnn.NMSBoxes(boxes1, confidences1, conf_threshold, nms_threshold)\n",
    "    for i in indices1:\n",
    "        number = 0\n",
    "        box = boxes1[i]\n",
    "        x = max(int(box[0]),0)\n",
    "        y = max(int(box[1]),0)\n",
    "        w = int(box[2])\n",
    "        h = int(box[3])\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (255,0,0), 2)\n",
    "        cv2.putText(image, america_class_names1[class_ids1[i]]+' LMFF,'+ str(\"%.2f\"%confidences1[i]), (x-10, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
    "\n",
    "\n",
    "    class_ids2 = []\n",
    "    confidences2 = []\n",
    "    boxes2 = []\n",
    "    count2 = 0\n",
    "    for out2 in outs2:\n",
    "        for detection2 in out2:\n",
    "            scores2=detection2[5:]\n",
    "            count2 += 1\n",
    "            class_id2 = np.argmax(scores2)\n",
    "            confidence2 = scores2[class_id2]\n",
    "            if confidence2 > conf_threshold:\n",
    "                center_x = int(detection2[0] * Width)\n",
    "                center_y = int(detection2[1] * Height)\n",
    "                w = int(detection2[2] * Width)\n",
    "                h = int(detection2[3] * Height)\n",
    "                x = center_x - w / 2\n",
    "                y = center_y - h / 2\n",
    "                class_ids2.append(class_id2)\n",
    "                confidences2.append(float(confidence2))\n",
    "                boxes2.append([x, y, w, h])\n",
    "    indices2 = cv2.dnn.NMSBoxes(boxes2, confidences2, conf_threshold, nms_threshold)\n",
    "    for i in indices2:\n",
    "        number = 0\n",
    "        box = boxes2[i]\n",
    "        x = max(int(box[0]),0)\n",
    "        y = max(int(box[1]),0)\n",
    "        w = int(box[2])\n",
    "        h = int(box[3])\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "        cv2.putText(image, america_class_names2[class_ids2[i]]+' AM,'+ str(\"%.2f\"%confidences2[i]), (x-10, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "    cv2.putText(image, str(imname.index(img_name)), (0,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "    vid_out.write(image)\n",
    "vid_out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da23d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='roi_lmff1'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "img_idx={'crop_name':[], 'imname': [], 'label': [], 'conf': [], 'bbox': []}\n",
    "for subdir, dirs, files in os.walk('lightmetrics_pic'):\n",
    "    for num,file in enumerate(files):\n",
    "        if '.jpg' in file:\n",
    "            image = cv2.imread(os.path.join(subdir, file))\n",
    "            gray_image= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            blob = cv2.dnn.blobFromImage(gray_image, scale, img_size, (0,0,0), True, crop=False)\n",
    "            net.setInput(blob)\n",
    "            outs1 = net.forward(get_output_layers(net))\n",
    "            class_ids1 = []\n",
    "            confidences1 = []\n",
    "            boxes1 = []\n",
    "            conf_threshold = 0.3\n",
    "            nms_threshold = 0.4\n",
    "            count1 = 0\n",
    "            for out1 in outs1:\n",
    "                for detection1 in out1:\n",
    "                    scores1=detection1[5:]\n",
    "                    count1 += 1\n",
    "                    class_id1 = np.argmax(scores1)\n",
    "                    confidence1 = scores1[class_id1]\n",
    "                    if confidence1 > conf_threshold:\n",
    "                        center_x = int(detection1[0] * Width)\n",
    "                        center_y = int(detection1[1] * Height)\n",
    "                        w = int(detection1[2] * Width)\n",
    "                        h = int(detection1[3] * Height)\n",
    "                        x = center_x - w / 2\n",
    "                        y = center_y - h / 2\n",
    "                        class_ids1.append(class_id1)\n",
    "                        confidences1.append(float(confidence1))\n",
    "                        boxes1.append([x, y, w, h])\n",
    "            indices1 = cv2.dnn.NMSBoxes(boxes1, confidences1, conf_threshold, nms_threshold)\n",
    "            for i in indices1:\n",
    "                number = 0\n",
    "                box = boxes1[i]\n",
    "                x = max(int(box[0]),0)\n",
    "                y = max(int(box[1]),0)\n",
    "                w = int(box[2])\n",
    "                h = int(box[3])\n",
    "                label = america_class_names[class_ids1[i]]\n",
    "                dst = os.path.join(path, label)\n",
    "                if not os.path.exists(dst):\n",
    "                    os.mkdir(dst)\n",
    "                crop_name = file.split('.')[0]+'____10_'+label+'_'+str(i)+'.jpg'\n",
    "                cv2.imwrite(os.path.join(dst,crop_name), image[y:y+h, x:x+w]) # num\n",
    "\n",
    "                img_idx['imname'].append(file)\n",
    "                img_idx['crop_name'].append(crop_name)\n",
    "                img_idx['label'].append(label)\n",
    "                img_idx['conf'].append(confidences1[i])\n",
    "                img_idx['bbox'].append([x,y,w,h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe72ee19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eventVideo_stop_sign_trip_master_2022_03_07_18_42_30_841_DF4B19E0366CBFF948266CD981333D6A872D682D_4l8fy_5_2022_03_07_19_53_43_511_primary.jpg',\n",
       " 'eventVideo_stop_sign_trip_master_2022_05_30_17_13_38_504_2DFC1BCEF31DF0D454A86B68D9CC478B5AE59A37_VvYC4_6_2022_05_30_18_12_00_167_primary.jpg',\n",
       " 'eventVideo_stop_sign_trip_master_2022_05_30_17_13_38_504_2DFC1BCEF31DF0D454A86B68D9CC478B5AE59A37_VvYC4_6_2022_05_30_18_12_00_167_primary.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_idx['imname'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15621abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('light_met_crop_lmff1.pickle', 'wb') as f:\n",
    "    pickle.dump(img_idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2bf0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, pickle, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "899b3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../lmff1.pickle' ,'rb') as f:\n",
    "    lmff = pickle.load(f)\n",
    "\n",
    "clas_a, images_a, embed1_a, metadata_a, color_a, clss_a = lmff['clas'], lmff['images'], lmff['embeddings'], lmff['metadata'], lmff['colors'], lmff['cls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "935cb767",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clss_a)):\n",
    "    if metadata_a[i] == 'lmff' and clss_a[i] == 'StopSign' and embed1_a[i][0]>5:\n",
    "        shutil.copy(os.path.join('roi_lmff/StopSign',clas_a[i]+'.jpg'),os.path.join('false_positives/lmff/StopSign', clas_a[i]+'.jpg'))\n",
    "        idx = clas_a[i].split('_')[-1]\n",
    "        for subdir, dirs, files in os.walk('roi_america'):\n",
    "            for file in files:\n",
    "                if '.jpg' in file:\n",
    "                    if idx == file.split('.')[0].split('_')[-1]:\n",
    "                        src = os.path.join(subdir, file)\n",
    "                        ds = os.path.join('false_positives/america', subdir.split('/')[-1])\n",
    "                        if not os.path.exists(ds):\n",
    "                            os.mkdir(ds)\n",
    "                        dst = os.path.join(ds, file)\n",
    "                        shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9741bf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'17'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clas_a[0].split('_')[-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f54e8d9",
   "metadata": {},
   "source": [
    "## Metapix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cba6972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc499074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'black',\n",
       " 'blue',\n",
       " 'brown',\n",
       " 'green',\n",
       " 'grey',\n",
       " 'no',\n",
       " 'orange',\n",
       " 'purple',\n",
       " 'red',\n",
       " 'silver',\n",
       " 'white'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../consolidated.csv')\n",
    "set(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ed1ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'black'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'][90] in colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d05bd3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "path = 'metapix'\n",
    "out_path = 'yolo_crop_metamix'\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if '.jpg' in file:\n",
    "            image = cv2.imread(os.path.join(subdir, file))\n",
    "            Height, Width = image.shape[:2]\n",
    "            blob = cv2.dnn.blobFromImage(image, scale, img_size, (0,0,0), True, crop=False)\n",
    "            net.setInput(blob)\n",
    "            outs = net.forward(get_output_layers(net))\n",
    "            max_conf = -1\n",
    "            for out in outs:\n",
    "                for detection in out:\n",
    "                    scores=detection[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    confidence = scores[class_id]\n",
    "                    if confidence > max_conf:\n",
    "                        center_x = int(detection[0] * Width)\n",
    "                        center_y = int(detection[1] * Height)\n",
    "                        w = int(detection[2] * Width)\n",
    "                        h = int(detection[3] * Height)\n",
    "                        x = int(center_x - w / 2)\n",
    "                        y = int(center_y - h / 2)\n",
    "                        max_conf = confidence\n",
    "            if not os.path.exists(os.path.join(out_path, subdir.split('/')[-2], subdir.split('/')[-1])):\n",
    "                os.mkdir(os.path.join(out_path, subdir.split('/')[-2], subdir.split('/')[-1]))\n",
    "            crop_img = image[y:y+h, x:x+w]\n",
    "            if crop_img.shape[0]>0 and crop_img.shape[1]>0:\n",
    "                cv2.imwrite(os.path.join(out_path, subdir.split('/')[-2], subdir.split('/')[-1], file), crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e72cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../metamix.pickle', 'wb') as f:\n",
    "    pickle.dump({'rgb': rgb, 'imname': imname, 'images': images, 'lbl': lbl, 'match': match}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eebeaacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], shape=(13, 0, 3), dtype=uint8), 0.0, -2, 0, 27, 13, (142, 244, 3))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[y:y+h, x:x+w], max_conf, x,y,w,h,image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8b1f261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image[y:y+h, x:x+w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72fd5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../consolidated.csv')\n",
    "label, match = df['label'], df['match']\n",
    "label = label.replace(['no'], ['pink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "923928f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['black', 'blue', 'brown', 'green', 'grey', 'no', 'orange',\n",
       "        'purple', 'red', 'silver', 'white'], dtype=object),\n",
       " array([203,  58,   2,  13,  80, 185,   3,   3,  49, 184, 205]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(df['label']), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f037da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "missing_image = np.load('../../missing_image.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe570ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0d682aa8-818e-436d-8cda-eb7a95f60dec.jpg',\n",
       "       '0dd19618-7a6d-435c-a921-cf24c83bc744.jpg',\n",
       "       '0a334e8f-080d-4109-a4d7-83e4c61e3ad1.jpg',\n",
       "       '0aef6170-9c48-4376-adc0-d8dbea7586b8.jpg',\n",
       "       '00a3af7c-3214-4665-a2df-a05600c72029.jpg',\n",
       "       '0c074cef-13f9-4c55-b5a5-5f6c53958f76.jpg',\n",
       "       '0b501543-567e-456d-b883-31ca5a2bd271.jpg',\n",
       "       '0d7e2e28-e87d-4584-b411-fd6dcc74cbcb.jpg',\n",
       "       '0ae0df2b-e98a-49fd-9241-a88609146c19.jpg',\n",
       "       '0a3461be-7d39-4a1d-ab18-a4e39f3ee88b.jpg',\n",
       "       '0c190cec-53ac-415e-9dbf-30293f85b913.jpg',\n",
       "       '0ac87efe-bfb1-41fd-9768-7c37ae08a149.jpg'], dtype='<U40')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_image[-12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b86a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
