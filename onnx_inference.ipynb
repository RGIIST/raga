{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "214dff6e-c096-4117-a3da-5715c21ec2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bc30c22-3e21-4ca1-b2e2-0ef3b33596c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non max suppression (nms) function\n",
    "def hard_nms(box_scores, iou_threshold, top_k=-1, candidate_size=200):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        box_scores (N, 5): boxes in corner-form and probabilities.\n",
    "        iou_threshold: intersection over union threshold.\n",
    "        top_k: keep top_k results. If k <= 0, keep all the results.\n",
    "        candidate_size: only consider the candidates with the highest scores.\n",
    "    Returns:\n",
    "         picked: a list of indexes of the kept boxes\n",
    "    \"\"\"\n",
    "    scores = box_scores[:, -1]\n",
    "    boxes = box_scores[:, :-1]\n",
    "    picked = []\n",
    "    _, indexes = scores.sort(descending=True)\n",
    "    indexes = indexes[:candidate_size]\n",
    "    while len(indexes) > 0:\n",
    "        current = indexes[0]\n",
    "        picked.append(current.item())\n",
    "        if 0 < top_k == len(picked) or len(indexes) == 1:\n",
    "            break\n",
    "        current_box = boxes[current, :]\n",
    "        indexes = indexes[1:]\n",
    "        rest_boxes = boxes[indexes, :]\n",
    "        iou = iou_of(\n",
    "            rest_boxes,\n",
    "            current_box.unsqueeze(0),\n",
    "        )\n",
    "        indexes = indexes[iou <= iou_threshold]\n",
    "\n",
    "    return box_scores[picked, :]\n",
    "\n",
    "#utility functions\n",
    "def iou_of(boxes0, boxes1, eps=1e-5):\n",
    "    \"\"\"Return intersection-over-union (Jaccard index) of boxes.\n",
    "    Args:\n",
    "        boxes0 (N, 4): ground truth boxes.\n",
    "        boxes1 (N or 1, 4): predicted boxes.\n",
    "        eps: a small number to avoid 0 as denominator.\n",
    "    Returns:\n",
    "        iou (N): IoU values.\n",
    "    \"\"\"\n",
    "    overlap_left_top = torch.max(boxes0[..., :2], boxes1[..., :2])\n",
    "    overlap_right_bottom = torch.min(boxes0[..., 2:], boxes1[..., 2:])\n",
    "\n",
    "    overlap_area = area_of(overlap_left_top, overlap_right_bottom)\n",
    "    area0 = area_of(boxes0[..., :2], boxes0[..., 2:])\n",
    "    area1 = area_of(boxes1[..., :2], boxes1[..., 2:])\n",
    "    return overlap_area / (area0 + area1 - overlap_area + eps)\n",
    "\n",
    "def area_of(left_top, right_bottom) -> torch.Tensor:\n",
    "    \"\"\"Compute the areas of rectangles given two corners.\n",
    "    Args:\n",
    "        left_top (N, 2): left top corner.\n",
    "        right_bottom (N, 2): right bottom corner.\n",
    "    Returns:\n",
    "        area (N): return the area.\n",
    "    \"\"\"\n",
    "    hw = torch.clamp(right_bottom - left_top, min=0.0)\n",
    "    return hw[..., 0] * hw[..., 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "108f325d-a6a3-412f-9414-32210842adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "image_size = 300\n",
    "image_mean = np.array([127, 127, 127])  # RGB layout\n",
    "image_std = 128.0\n",
    "iou_threshold = 0.45\n",
    "center_variance = 0.1\n",
    "size_variance = 0.2\n",
    "\n",
    "filter_threshold = 0.25\n",
    "candidate_size=200\n",
    "sigma=0.5\n",
    "top_k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec7bffab-3e2f-48c6-9b76-3c3846b44c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 15:06:00.596383457 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:509 CreateExecutionProviderInstance] Failed to create TensorrtExecutionProvider. Please reference https://onnxruntime.ai/docs/execution-providers/TensorRT-ExecutionProvider.html#requirements to ensure all dependencies are met.\n"
     ]
    }
   ],
   "source": [
    "#loading image and image preprocessing \n",
    "image_path = 'SampleFrames_for_Baselineline/frame00448.jpg'\n",
    "\n",
    "orig_image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n",
    "height, width, _ = image.shape\n",
    "\n",
    "image = cv2.resize(image, (image_size, image_size))\n",
    "image = image.astype(np.float32)\n",
    "image -= image_mean\n",
    "image = image/image_std\n",
    "# image = torch.from_numpy(image.astype(np.float32)).permute(2, 0, 1)\n",
    "# images = image.unsqueeze(0)\n",
    "# numpy equivalent of above torch method\n",
    "image = image.transpose((2, 0, 1))\n",
    "images = np.expand_dims(image, 0)\n",
    "\n",
    "# images = images.cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "#loading onnx model and inferencing\n",
    "ort_session = onnxruntime.InferenceSession(\"models/baseline_model.onnx\",\n",
    "                                           providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', \n",
    "                                                      'CPUExecutionProvider'])\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: images}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "import json\n",
    "result=[]\n",
    "for i in range(3000):\n",
    "    result.append({'conf':ort_outs[0][0][i].tolist(),'bbox':ort_outs[1][0][i].tolist()})\n",
    "with open('results/frame448_onnx-josh.json','w') as f:\n",
    "    json.dump(result,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5d36f0e-d43a-41b0-ab59-36e89ea0bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_422 = ort_outs[0][0].flatten().tolist()\n",
    "data_471 = ort_outs[1][0].flatten().tolist()\n",
    "with open('_ns_422_bub.txt', 'w') as f:\n",
    "    for line in data_422:\n",
    "        f.write(f\"{line}\\n\")\n",
    "with open('_ns_471_bub.txt', 'w') as f:\n",
    "    for line in data_471:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14dfa4a4-1f5c-49f1-ab3f-232092e70ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[9.8295951e-01, 1.3772622e-04, 3.8826594e-04, ...,\n",
      "         2.9158141e-04, 8.6010905e-04, 1.1549543e-04],\n",
      "        [9.8894602e-01, 7.9930515e-04, 1.4301903e-03, ...,\n",
      "         6.5930543e-04, 1.6731346e-03, 3.1344703e-04],\n",
      "        [9.7481370e-01, 2.2204932e-04, 7.9939316e-04, ...,\n",
      "         4.8207736e-04, 2.2071155e-03, 2.5556624e-04],\n",
      "        ...,\n",
      "        [9.8741257e-01, 3.6753128e-05, 6.4116875e-03, ...,\n",
      "         1.9436853e-05, 4.1402732e-03, 2.0046044e-05],\n",
      "        [9.8401690e-01, 3.0069516e-05, 5.6354385e-03, ...,\n",
      "         2.2533295e-05, 8.5932463e-03, 2.3950246e-05],\n",
      "        [9.7707158e-01, 4.6546724e-05, 7.4633746e-03, ...,\n",
      "         2.6527547e-05, 1.2634422e-02, 2.7220520e-05]]], dtype=float32), array([[[ 0.04295783, -0.00497538,  0.07433966,  0.07776529],\n",
      "        [-0.07389446, -0.08710002,  0.12798768,  0.16818765],\n",
      "        [ 0.07898747, -0.00732234,  0.11466733,  0.07174507],\n",
      "        ...,\n",
      "        [ 0.23108721,  0.15713984,  0.77595186,  0.8258249 ],\n",
      "        [ 0.15813333,  0.21930078,  0.83936685,  0.6765027 ],\n",
      "        [ 0.28879905,  0.17163202,  0.71925926,  0.8234887 ]]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#onnx output format\n",
    "print(ort_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "837b4a13-8225-4e01-9073-de0c6704b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxes\n",
      "torch.Size([3000, 4])\n",
      "tensor([[ 0.0430, -0.0050,  0.0743,  0.0778],\n",
      "        [-0.0739, -0.0871,  0.1280,  0.1682],\n",
      "        [ 0.0790, -0.0073,  0.1147,  0.0717],\n",
      "        ...,\n",
      "        [ 0.2311,  0.1571,  0.7760,  0.8258],\n",
      "        [ 0.1581,  0.2193,  0.8394,  0.6765],\n",
      "        [ 0.2888,  0.1716,  0.7193,  0.8235]])\n",
      "\n",
      "scores\n",
      "torch.Size([3000, 11])\n",
      "tensor([[9.8296e-01, 1.3773e-04, 3.8827e-04,  ..., 2.9158e-04, 8.6011e-04,\n",
      "         1.1550e-04],\n",
      "        [9.8895e-01, 7.9931e-04, 1.4302e-03,  ..., 6.5931e-04, 1.6731e-03,\n",
      "         3.1345e-04],\n",
      "        [9.7481e-01, 2.2205e-04, 7.9939e-04,  ..., 4.8208e-04, 2.2071e-03,\n",
      "         2.5557e-04],\n",
      "        ...,\n",
      "        [9.8741e-01, 3.6753e-05, 6.4117e-03,  ..., 1.9437e-05, 4.1403e-03,\n",
      "         2.0046e-05],\n",
      "        [9.8402e-01, 3.0070e-05, 5.6354e-03,  ..., 2.2533e-05, 8.5932e-03,\n",
      "         2.3950e-05],\n",
      "        [9.7707e-01, 4.6547e-05, 7.4634e-03,  ..., 2.6528e-05, 1.2634e-02,\n",
      "         2.7221e-05]])\n"
     ]
    }
   ],
   "source": [
    "#bounding box and scores\n",
    "\n",
    "scores, boxes = ort_outs\n",
    "boxes = torch.from_numpy(boxes[0])\n",
    "scores = torch.from_numpy(scores[0])\n",
    "\n",
    "print('boxes')\n",
    "print(boxes.size())\n",
    "print(boxes)\n",
    "print('')\n",
    "print('scores')\n",
    "print(scores.size())\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7789127-0390-4fb2-bc76-cd2c297ab6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bounding box decoding and extracting top_k detections above prob_threshold\n",
    "\n",
    "prob_threshold = filter_threshold\n",
    "picked_box_probs = []\n",
    "picked_labels = []\n",
    "for class_index in range(1, scores.size(1)):\n",
    "    probs = scores[:, class_index]\n",
    "    mask = probs > prob_threshold\n",
    "    probs = probs[mask]\n",
    "    if probs.size(0) == 0:\n",
    "        continue\n",
    "    subset_boxes = boxes[mask, :]\n",
    "    box_probs = torch.cat([subset_boxes, probs.reshape(-1, 1)], dim=1)\n",
    "    box_probs = hard_nms(box_probs,iou_threshold, top_k, candidate_size)\n",
    "    picked_box_probs.append(box_probs)\n",
    "    picked_labels.extend([class_index] * box_probs.size(0))\n",
    "if not picked_box_probs:\n",
    "    boxes, labels, probs = torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
    "else:\n",
    "    picked_box_probs = torch.cat(picked_box_probs)\n",
    "    picked_box_probs[:, 0] *= width\n",
    "    picked_box_probs[:, 1] *= height\n",
    "    picked_box_probs[:, 2] *= width\n",
    "    picked_box_probs[:, 3] *= height\n",
    "    boxes, labels, probs = picked_box_probs[:, :4], torch.tensor(picked_labels), picked_box_probs[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8cfcd28a-fa87-4e28-bb64-dadd651a3251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding boxes\n",
      "tensor([[2654.9373, 1231.6953, 3411.1221, 1679.4271],\n",
      "        [3645.2175, 1286.9338, 3836.7449, 1368.8589]])\n",
      "\n",
      "labels\n",
      "tensor([9, 9])\n",
      "\n",
      "probability/confidence scores\n",
      "tensor([0.9968, 0.3093])\n"
     ]
    }
   ],
   "source": [
    "#final bonding box detections, labels and prob/confidence scores\n",
    "\n",
    "print('bounding boxes')\n",
    "print(boxes)\n",
    "print('')\n",
    "print('labels')\n",
    "print(labels)\n",
    "print('')\n",
    "print('probability/confidence scores')\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec20785d-1521-4bcd-9d6b-7238a7ad876b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "6a39d376-e4df-4c50-8935-f4165087bee5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe7f96de-95b7-472e-9103-d850ddd2ec02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f715d3d-d61c-448b-a7bf-a893ac181838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
